{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import scipy, scipy.io\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import *\n",
    "from matplotlib import pyplot as plt\n",
    "import itertools\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# pretty charting\n",
    "# import seaborn as sns\n",
    "# sns.set_palette('muted')\n",
    "# sns.set_style('darkgrid')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadmat(filename):\n",
    "    '''\n",
    "    this function should be called instead of direct spio.loadmat\n",
    "    as it cures the problem of not properly recovering python dictionaries\n",
    "    from mat files. It calls the function check keys to cure all entries\n",
    "    which are still mat-objects\n",
    "    '''\n",
    "    data = scipy.io.loadmat(filename, struct_as_record=False, squeeze_me=True)\n",
    "    return _check_keys(data)\n",
    "\n",
    "def _check_keys(dict):\n",
    "    '''\n",
    "    checks if entries in dictionary are mat-objects. If yes\n",
    "    todict is called to change them to nested dictionaries\n",
    "    '''\n",
    "    for key in dict:\n",
    "        if isinstance(dict[key], scipy.io.matlab.mio5_params.mat_struct):\n",
    "            dict[key] = _todict(dict[key])\n",
    "    return dict        \n",
    "\n",
    "def _todict(matobj):\n",
    "    '''\n",
    "    A recursive function which constructs from matobjects nested dictionaries\n",
    "    '''\n",
    "    dict = {}\n",
    "    for strg in matobj._fieldnames:\n",
    "        elem = matobj.__dict__[strg]\n",
    "        if isinstance(elem, scipy.io.matlab.mio5_params.mat_struct):\n",
    "            dict[strg] = _todict(elem)\n",
    "        elif isinstance(elem,np.ndarray):\n",
    "            dict[strg] = _tolist(elem)\n",
    "        else:\n",
    "            dict[strg] = elem\n",
    "    return dict\n",
    "\n",
    "def _tolist(ndarray):\n",
    "    '''\n",
    "    A recursive function which constructs lists from cellarrays \n",
    "    (which are loaded as numpy ndarrays), recursing into the elements\n",
    "    if they contain matobjects.\n",
    "    '''\n",
    "    elem_list = []            \n",
    "    for sub_elem in ndarray:\n",
    "        if isinstance(sub_elem, scipy.io.matlab.mio5_params.mat_struct):\n",
    "            elem_list.append(_todict(sub_elem))\n",
    "        elif isinstance(sub_elem,np.ndarray):\n",
    "            elem_list.append(_tolist(sub_elem))\n",
    "        else:\n",
    "            elem_list.append(sub_elem)\n",
    "    return elem_list\n",
    "\n",
    "def convertMatToJSON(matData, fileName):\n",
    "    for key in matData.keys():\n",
    "        if (type(matData[key])) is np.ndarray:\n",
    "            serializedData = pickle.dumps(matData[key], protocol=0) # protocol 0 is printable ASCII\n",
    "            jsonData[key] = serializedData\n",
    "        else:\n",
    "            jsonData[key] = matData[key]\n",
    "\n",
    "    with contextlib.closing(bz2.BZ2File(fileName, 'wb')) as f:\n",
    "        json.dump(jsonData, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def degreeofagree(ezset, cezset, allset):\n",
    "    notcez = list(set(allset) - set(cezset))\n",
    "    cez_int_eez = list(set(cezset) & set(ezset))\n",
    "    notcez_int_eez = list(set(notcez) - set(ezset))\n",
    "    \n",
    "    term1 = len(cez_int_eez) / len(cezset)\n",
    "    term2 = len(notcez_int_eez) / len(notcez)\n",
    "    \n",
    "    doa = term1 - term2\n",
    "    return doa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pt2aw2_fragilitystats.mat', 'pt2aslp2_fragilitystats.mat', 'pt2aslp1_fragilitystats.mat', 'pt2aw1_fragilitystats.mat', 'pt1aslp1_fragilitystats.mat', 'pt1aslp2_fragilitystats.mat', 'pt3aslp1_fragilitystats.mat', 'pt1aw1_fragilitystats.mat', 'pt3aw1_fragilitystats.mat', 'pt1aw2_fragilitystats.mat', 'pt3aslp2_fragilitystats.mat']\n"
     ]
    }
   ],
   "source": [
    "dataDir = '/Users/adam2392/Documents/adamli/fragility_dataanalysis/' + \\\n",
    "    'figures/fragilityStats/notchfilter/perturbationC_win250_step125_radius1.5/interictal'\n",
    "filelist = os.listdir(dataDir)\n",
    "print filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient  does not work\n",
      "min_frag  does not work\n",
      "max_frag  does not work\n",
      "ez_asymmetry  does not work\n",
      "resected_asymmetry  does not work\n",
      "network_fragility  does not work\n",
      "[ 0.27357749  0.30325798  0.24111201  0.22957369  0.04896799  0.03830918\n",
      "  0.30077524  0.31213898  0.21868333  0.30065526  0.14204959  0.28387752\n",
      "  0.34611963  0.26452052  0.31041356  0.26842786  0.15048332  0.24605565\n",
      "  0.30406817  0.32804863  0.22440111  0.12967992  0.30125781  0.2022697\n",
      "  0.02060447  0.17987869  0.22933054  0.28340147  0.30243579  0.2640878\n",
      "  0.50415134  0.06476604  0.08212339  0.28748599  0.19657617  0.05409319\n",
      "  0.35445641  0.31553575  0.54335985  0.26957417  0.3367482   0.26456796\n",
      "  1.          0.36076984  0.36313026  0.22209041  0.28282473  0.39524566\n",
      "  0.32659685  0.40405091  0.02272254  0.31292851  0.32097206  0.24192412\n",
      "  0.34111468  0.36505899  0.34099752  0.25347234  0.28330824  0.34822033\n",
      "  0.3619783   0.37849143  0.31315354]\n",
      "[ 1.]\n"
     ]
    }
   ],
   "source": [
    "# thresholds to set on the preictal, ictal times of coefficient of variation / other frag stats\n",
    "thresholds = [0.7, 0.8, 0.9, 0.95, 0.99]\n",
    "\n",
    "nih_doas = np.zeros((len(filelist), len(thresholds)))\n",
    "\n",
    "# Load each dataset's fragility statistics results\n",
    "for idx, fil in enumerate(filelist):\n",
    "    datastruct = loadmat(os.path.join(dataDir, fil))\n",
    "    features = datastruct['features_struct']\n",
    "    \n",
    "    colnames = features.keys()\n",
    "    for col in colnames:\n",
    "        try:\n",
    "            features[col] = features[col]/max(features[col])\n",
    "        except:\n",
    "            print col, \" does not work\"\n",
    "    # extract all the fragility stats\n",
    "    patient = features['patient']\n",
    "    min_frag = features['min_frag']\n",
    "    max_frag = features['max_frag']\n",
    "    ez_asymmetry = features['ez_asymmetry']\n",
    "    resected_asymmetry = features['resected_asymmetry']\n",
    "    network_fragility = features['network_fragility']\n",
    "    cfvar_time = features['cfvar_time']\n",
    "    cfvar_chan = features['cfvar_chan']\n",
    "    channels = features['included_labels']\n",
    "    cezset = features['ezone_labels']\n",
    "    \n",
    "    # only if the dataset was ictal\n",
    "#     precfvar_chan = features['precfvar_chan']\n",
    "#     postcfvar_chan = features['postcfvar_chan']\n",
    "#     post20cfvar_chan = features['post20cfvar_chan']\n",
    "#     post30cfvar_chan = features['post30cfvar_chan']\n",
    "#     post40cfvar_chan = features['post40cfvar_chan']\n",
    "#     post50cfvar_chan = features['post50cfvar_chan']\n",
    "    \n",
    "    # go through each threshold and determine set of electrodes within EZ set\n",
    "    print cfvar_chan\n",
    "    \n",
    "    # extract the clinical meta data for this patient\n",
    "    \n",
    "    pat_doas = np.zeros((1, len(threholds)))\n",
    "    for jdx, threshold in enumerate(thresholds):\n",
    "        cfvar_threshed = cfvar_chan[cfvar_chan >= threshold]\n",
    "        cfvar_chan = channels[cfvar_chan >= threshold]\n",
    "        \n",
    "        # compute doa\n",
    "        doa_threshold = degreeofagree(cfvar_chan, cezset, channels)\n",
    "        \n",
    "        # store the channel for this threshold\n",
    "        pat_doas[0, jdx] = doa_threshold\n",
    "        break\n",
    "    break\n",
    "    \n",
    "    \n",
    "    print max(cfvar_chan)\n",
    "    print max(precfvar_chan)\n",
    "    print max(postcfvar_chan)\n",
    "    # create an array of the coefficient of variations of this patient \n",
    "    rowarray = np.array(([cfvar_chan, precfvar_chan, \\\n",
    "                         postcfvar_chan, post20cfvar_chan, \\\n",
    "                         post30cfvar_chan, post40cfvar_chan, post50cfvar_chan]))\n",
    "    print patient\n",
    "    if idx == 0:\n",
    "        feature_df = pd.DataFrame(rowarray, columns=['cf var', 'pre cf var', 'post10 cfv', \\\n",
    "                                                    'post20 cfv', 'post30 cfv', \\\n",
    "                                                    'post40 cfv', 'post50 cfv'])\n",
    "    else:\n",
    "        row_df = pd.DataFrame(rowarray, ignore_index=True)\n",
    "        feature_df.append(row_df, ignore_index=True)\n",
    "    \n",
    "    display(feature_df)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['patient', 'min_frag', 'max_frag', 'ez_asymmetry', 'resected_asymmetry', 'network_fragility', 'cfvar_chan', 'high_frag', 'cfvar_time']\n"
     ]
    }
   ],
   "source": [
    "print features.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
