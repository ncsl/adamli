{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os, glob\n",
    "import scipy, scipy.io\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import *\n",
    "from matplotlib import pyplot as plt\n",
    "import itertools\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from itertools import compress\n",
    "\n",
    "import sys\n",
    "sys.path.append('/usr/local/lib/python2.7/site-packages')\n",
    "\n",
    "# pretty charting\n",
    "import seaborn as sns\n",
    "sns.set_palette('muted')\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadmat(filename):\n",
    "    '''\n",
    "    this function should be called instead of direct spio.loadmat\n",
    "    as it cures the problem of not properly recovering python dictionaries\n",
    "    from mat files. It calls the function check keys to cure all entries\n",
    "    which are still mat-objects\n",
    "    '''\n",
    "    data = scipy.io.loadmat(filename, struct_as_record=False, squeeze_me=True)\n",
    "    return _check_keys(data)\n",
    "\n",
    "def _check_keys(dict):\n",
    "    '''\n",
    "    checks if entries in dictionary are mat-objects. If yes\n",
    "    todict is called to change them to nested dictionaries\n",
    "    '''\n",
    "    for key in dict:\n",
    "        if isinstance(dict[key], scipy.io.matlab.mio5_params.mat_struct):\n",
    "            dict[key] = _todict(dict[key])\n",
    "    return dict        \n",
    "\n",
    "def _todict(matobj):\n",
    "    '''\n",
    "    A recursive function which constructs from matobjects nested dictionaries\n",
    "    '''\n",
    "    dict = {}\n",
    "    for strg in matobj._fieldnames:\n",
    "        elem = matobj.__dict__[strg]\n",
    "        if isinstance(elem, scipy.io.matlab.mio5_params.mat_struct):\n",
    "            dict[strg] = _todict(elem)\n",
    "        elif isinstance(elem,np.ndarray):\n",
    "            dict[strg] = _tolist(elem)\n",
    "        else:\n",
    "            dict[strg] = elem\n",
    "    return dict\n",
    "\n",
    "def _tolist(ndarray):\n",
    "    '''\n",
    "    A recursive function which constructs lists from cellarrays \n",
    "    (which are loaded as numpy ndarrays), recursing into the elements\n",
    "    if they contain matobjects.\n",
    "    '''\n",
    "    elem_list = []            \n",
    "    for sub_elem in ndarray:\n",
    "        if isinstance(sub_elem, scipy.io.matlab.mio5_params.mat_struct):\n",
    "            elem_list.append(_todict(sub_elem))\n",
    "        elif isinstance(sub_elem,np.ndarray):\n",
    "            elem_list.append(_tolist(sub_elem))\n",
    "        else:\n",
    "            elem_list.append(sub_elem)\n",
    "    return elem_list\n",
    "\n",
    "def convertMatToJSON(matData, fileName):\n",
    "    for key in matData.keys():\n",
    "        if (type(matData[key])) is np.ndarray:\n",
    "            serializedData = pickle.dumps(matData[key], protocol=0) # protocol 0 is printable ASCII\n",
    "            jsonData[key] = serializedData\n",
    "        else:\n",
    "            jsonData[key] = matData[key]\n",
    "\n",
    "    with contextlib.closing(bz2.BZ2File(fileName, 'wb')) as f:\n",
    "        json.dump(jsonData, f)\n",
    "        \n",
    "def degreeofagree(ezset, cezset, allset):\n",
    "    notcez = list(set(allset) - set(cezset))\n",
    "    cez_int_eez = list(set(cezset) & set(ezset))\n",
    "    notcez_int_eez = list(set(notcez) - set(ezset))\n",
    "    \n",
    "    term1 = len(cez_int_eez) / len(cezset)\n",
    "    term2 = len(notcez_int_eez) / len(notcez)\n",
    "    \n",
    "    doa = term1 - term2\n",
    "    return doa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataDir = '/Users/adam2392/Documents/adamli/fragility_dataanalysis/' + \\\n",
    "    'figures/fragilityStats/notchfilter/perturbationC_win250_step125_radius1.5/ictal/success'\n",
    "filelist = glob.glob(os.path.join(dataDir, '*.mat'))\n",
    "\n",
    "print filelist\n",
    "\n",
    "# thresholds to set on the preictal, ictal times of coefficient of variation / other frag stats\n",
    "thresholds = [0.7, 0.8, 0.9, 0.95, 0.99]\n",
    "\n",
    "nih_doas = np.zeros((len(filelist), len(thresholds)))\n",
    "nih_ezsets = np.array(())\n",
    "nih_pats = []\n",
    "# Load each dataset's fragility statistics results\n",
    "for idx, fil in enumerate(filelist):\n",
    "    datastruct = loadmat(os.path.join(dataDir, fil))\n",
    "    features = datastruct['features_struct']\n",
    "\n",
    "    colnames = features.keys()\n",
    "    for col in colnames:\n",
    "        try:\n",
    "            features[col] = features[col]/max(features[col])\n",
    "        except:\n",
    "            1+1\n",
    "#             print col, \" does not work\"\n",
    "    # extract all the fragility stats\n",
    "    patient = features['patient']\n",
    "    min_frag = features['min_frag']\n",
    "    max_frag = features['max_frag']\n",
    "    ez_asymmetry = features['ez_asymmetry']\n",
    "    resected_asymmetry = features['resected_asymmetry']\n",
    "    network_fragility = features['network_fragility']\n",
    "    cfvar_time = features['cfvar_time']\n",
    "    cfvar_chan = features['cfvar_chan']\n",
    "    channels = features['included_labels']\n",
    "    cezset = features['ezone_labels']\n",
    "\n",
    "    # only if the dataset was ictal\n",
    "    precfvar_chan = features['precfvar_chan']\n",
    "    postcfvar_chan = features['postcfvar_chan']\n",
    "    post20cfvar_chan = features['post20cfvar_chan']\n",
    "    post30cfvar_chan = features['post30cfvar_chan']\n",
    "    post40cfvar_chan = features['post40cfvar_chan']\n",
    "    post50cfvar_chan = features['post50cfvar_chan']\n",
    "\n",
    "    # extract the clinical meta data for this patient\n",
    "\n",
    "    # go through each threshold and determine set of electrodes within EZ set \n",
    "    pat_doas = np.zeros((1, len(thresholds)))\n",
    "    pat_ezsets = []\n",
    "    for jdx, threshold in enumerate(thresholds):\n",
    "        # get the indices that pass threshold for coefficient of variation\n",
    "        cfvar_threshed_ind = post50cfvar_chan >= threshold\n",
    "\n",
    "        # get the actual cv and the electrode name\n",
    "        cfvar_threshed = list(compress(post50cfvar_chan, cfvar_threshed_ind))\n",
    "        ezset = list(compress(channels, cfvar_threshed_ind))\n",
    "\n",
    "        # compute doa\n",
    "        doa_threshold = degreeofagree(ezset, cezset, channels)\n",
    "\n",
    "        # store the channel for this threshold\n",
    "        pat_doas[0, jdx] = doa_threshold\n",
    "        pat_ezsets.append(np.array(ezset))\n",
    "\n",
    "    # convert the patient ez sets into an np array\n",
    "    pat_ezsets = np.array(pat_ezsets).reshape(len(thresholds), 1)\n",
    "\n",
    "    # store the pats in a list\n",
    "    nih_pats.append(patient)\n",
    "\n",
    "    # store the pat ez sets \n",
    "    if nih_ezsets.size == 0:\n",
    "        nih_ezsets = pat_ezsets\n",
    "    else:\n",
    "        nih_ezsets = np.append(nih_ezsets, pat_ezsets, axis=1)\n",
    "\n",
    "    # store the pat doa into the center doa array\n",
    "    nih_doas[idx, :] = pat_doas\n",
    "\n",
    "# print nih_pats\n",
    "# print nih_ezsets\n",
    "# print nih_doas\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.title('NIH Degree of Agreement Coefficient of Var for Success')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Degree of Agreement')\n",
    "g = sns.boxplot(pd.DataFrame(nih_doas))\n",
    "xticklabels = g.get_xticklabels()\n",
    "g.set_xticklabels([str(threshold) for threshold in thresholds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataDir = '/Users/adam2392/Documents/adamli/fragility_dataanalysis/' + \\\n",
    "    'figures/fragilityStats/notchfilter/perturbationC_win250_step125_radius1.5/ictal/failure'\n",
    "filelist = glob.glob(os.path.join(dataDir, '*.mat'))\n",
    "\n",
    "print filelist\n",
    "\n",
    "# thresholds to set on the preictal, ictal times of coefficient of variation / other frag stats\n",
    "thresholds = [0.7, 0.8, 0.9, 0.95, 0.99]\n",
    "\n",
    "nih_doas = np.zeros((len(filelist), len(thresholds)))\n",
    "nih_ezsets = np.array(())\n",
    "nih_pats = []\n",
    "# Load each dataset's fragility statistics results\n",
    "for idx, fil in enumerate(filelist):\n",
    "    datastruct = loadmat(os.path.join(dataDir, fil))\n",
    "    features = datastruct['features_struct']\n",
    "\n",
    "    colnames = features.keys()\n",
    "    for col in colnames:\n",
    "        try:\n",
    "            features[col] = features[col]/max(features[col])\n",
    "        except:\n",
    "            1+1\n",
    "#             print col, \" does not work\"\n",
    "    # extract all the fragility stats\n",
    "    patient = features['patient']\n",
    "    min_frag = features['min_frag']\n",
    "    max_frag = features['max_frag']\n",
    "    ez_asymmetry = features['ez_asymmetry']\n",
    "    resected_asymmetry = features['resected_asymmetry']\n",
    "    network_fragility = features['network_fragility']\n",
    "    cfvar_time = features['cfvar_time']\n",
    "    cfvar_chan = features['cfvar_chan']\n",
    "    channels = features['included_labels']\n",
    "    cezset = features['ezone_labels']\n",
    "\n",
    "    # only if the dataset was ictal\n",
    "    precfvar_chan = features['precfvar_chan']\n",
    "    postcfvar_chan = features['postcfvar_chan']\n",
    "    post20cfvar_chan = features['post20cfvar_chan']\n",
    "    post30cfvar_chan = features['post30cfvar_chan']\n",
    "    post40cfvar_chan = features['post40cfvar_chan']\n",
    "    post50cfvar_chan = features['post50cfvar_chan']\n",
    "\n",
    "    # extract the clinical meta data for this patient\n",
    "\n",
    "    # go through each threshold and determine set of electrodes within EZ set \n",
    "    pat_doas = np.zeros((1, len(thresholds)))\n",
    "    pat_ezsets = []\n",
    "    for jdx, threshold in enumerate(thresholds):\n",
    "        # get the indices that pass threshold for coefficient of variation\n",
    "        cfvar_threshed_ind = post50cfvar_chan >= threshold\n",
    "\n",
    "        # get the actual cv and the electrode name\n",
    "        cfvar_threshed = list(compress(post50cfvar_chan, cfvar_threshed_ind))\n",
    "        ezset = list(compress(channels, cfvar_threshed_ind))\n",
    "\n",
    "        # compute doa\n",
    "        doa_threshold = degreeofagree(ezset, cezset, channels)\n",
    "\n",
    "        # store the channel for this threshold\n",
    "        pat_doas[0, jdx] = doa_threshold\n",
    "        pat_ezsets.append(np.array(ezset))\n",
    "\n",
    "    # convert the patient ez sets into an np array\n",
    "    pat_ezsets = np.array(pat_ezsets).reshape(len(thresholds), 1)\n",
    "\n",
    "    # store the pats in a list\n",
    "    nih_pats.append(patient)\n",
    "\n",
    "    # store the pat ez sets \n",
    "    if nih_ezsets.size == 0:\n",
    "        nih_ezsets = pat_ezsets\n",
    "    else:\n",
    "        nih_ezsets = np.append(nih_ezsets, pat_ezsets, axis=1)\n",
    "\n",
    "    # store the pat doa into the center doa array\n",
    "    nih_doas[idx, :] = pat_doas\n",
    "\n",
    "# print nih_pats\n",
    "# print nih_ezsets\n",
    "# print nih_doas\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.title('NIH Degree of Agreement Coefficient of Var for Failure')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Degree of Agreement')\n",
    "g = sns.boxplot(pd.DataFrame(nih_doas))\n",
    "xticklabels = g.get_xticklabels()\n",
    "g.set_xticklabels([str(threshold) for threshold in thresholds])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
