{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fragility Data Analysis\n",
    "Using this notebook to prototype the functionality for the fragility algorithm (EpiMAP).\n",
    "\n",
    "Run through this notebook and change the parameters for the file directory, interictal or not, and patient names to create compressed json data files.\n",
    "\n",
    "These json data files can then be stored optimally on a database, such as MongoDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from IPython.display import display\n",
    "import os\n",
    "\n",
    "import scipy, scipy.io\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "\n",
    "import gzip\n",
    "import cStringIO\n",
    "import bz2,json,contextlib\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import *\n",
    "from matplotlib import pyplot as plt\n",
    "import itertools\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "# pretty charting\n",
    "import seaborn as sns\n",
    "sns.set_palette('muted')\n",
    "sns.set_style('darkgrid')\n",
    "from natsort import natsorted, ns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "## sklearn imports\n",
    "import sklearn.linear_model\n",
    "import sklearn.cross_validation\n",
    "import sklearn.tree\n",
    "import sklearn.ensemble\n",
    "import sklearn.preprocessing\n",
    "import sklearn.feature_selection\n",
    "import sklearn.pipeline\n",
    "import sklearn.grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadmat(filename):\n",
    "    '''\n",
    "    this function should be called instead of direct spio.loadmat\n",
    "    as it cures the problem of not properly recovering python dictionaries\n",
    "    from mat files. It calls the function check keys to cure all entries\n",
    "    which are still mat-objects\n",
    "    '''\n",
    "    data = scipy.io.loadmat(filename, struct_as_record=False, squeeze_me=True)\n",
    "    return _check_keys(data)\n",
    "\n",
    "def _check_keys(dict):\n",
    "    '''\n",
    "    checks if entries in dictionary are mat-objects. If yes\n",
    "    todict is called to change them to nested dictionaries\n",
    "    '''\n",
    "    for key in dict:\n",
    "        if isinstance(dict[key], scipy.io.matlab.mio5_params.mat_struct):\n",
    "            dict[key] = _todict(dict[key])\n",
    "    return dict        \n",
    "\n",
    "def _todict(matobj):\n",
    "    '''\n",
    "    A recursive function which constructs from matobjects nested dictionaries\n",
    "    '''\n",
    "    dict = {}\n",
    "    for strg in matobj._fieldnames:\n",
    "        elem = matobj.__dict__[strg]\n",
    "        if isinstance(elem, scipy.io.matlab.mio5_params.mat_struct):\n",
    "            dict[strg] = _todict(elem)\n",
    "        elif isinstance(elem,np.ndarray):\n",
    "            dict[strg] = _tolist(elem)\n",
    "        else:\n",
    "            dict[strg] = elem\n",
    "    return dict\n",
    "\n",
    "def _tolist(ndarray):\n",
    "    '''\n",
    "    A recursive function which constructs lists from cellarrays \n",
    "    (which are loaded as numpy ndarrays), recursing into the elements\n",
    "    if they contain matobjects.\n",
    "    '''\n",
    "    elem_list = []            \n",
    "    for sub_elem in ndarray:\n",
    "        if isinstance(sub_elem, scipy.io.matlab.mio5_params.mat_struct):\n",
    "            elem_list.append(_todict(sub_elem))\n",
    "        elif isinstance(sub_elem,np.ndarray):\n",
    "            elem_list.append(_tolist(sub_elem))\n",
    "        else:\n",
    "            elem_list.append(sub_elem)\n",
    "    return elem_list\n",
    "\n",
    "def convertMatToJSON(matData, fileName):\n",
    "    for key in matData.keys():\n",
    "        if (type(matData[key])) is np.ndarray:\n",
    "            serializedData = pickle.dumps(matData[key], protocol=0) # protocol 0 is printable ASCII\n",
    "            jsonData[key] = serializedData\n",
    "        else:\n",
    "            jsonData[key] = matData[key]\n",
    "\n",
    "    with contextlib.closing(bz2.BZ2File(fileName, 'wb')) as f:\n",
    "        json.dump(jsonData, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXTERNAL IS:  1\n"
     ]
    }
   ],
   "source": [
    "## Take .mat EEG files and convert them to .json data\n",
    "\n",
    "patients = [\n",
    "#             'pt1sz2', 'pt1sz3', 'pt1sz4', \\\n",
    "#             'pt2sz1', 'pt2sz3', \n",
    "            'pt2sz4', \\\n",
    "            'pt3sz2', 'pt3sz4', 'pt6sz3', 'pt6sz4', 'pt6sz5', \\\n",
    "            'pt7sz19', 'pt7sz21', 'pt7sz22', \\\n",
    "            'pt8sz1', 'pt8sz2', 'pt8sz3', \\\n",
    "            'JH101sz1', 'JH101sz2', 'JH101sz3', 'JH101sz4', \\\n",
    "            'JH102sz1', 'JH102sz2', 'JH102sz3', 'JH102sz4', 'JH102sz5', 'JH102sz6', \\\n",
    "            'JH103sz1', 'JH103sz2', 'JH103sz3', \\\n",
    "            'JH104sz1', 'JH104sz2', 'JH104sz3', \\\n",
    "            'JH105sz1', 'JH105sz2', 'JH105sz3', 'JH105sz4', 'JH105sz5',\\\n",
    "            'JH106sz1', 'JH106sz2', 'JH106sz3', 'JH106sz4', 'JH106sz5', 'JH106sz6', \\\n",
    "            'JH107sz1', 'JH107sz2', 'JH107sz3', 'JH107sz4', 'JH107sz5', 'JH107sz6', 'JH107sz7', 'JH107sz8', 'JH107sz9', \\\n",
    "            'JH108sz1', 'JH108sz2', 'JH108sz3', 'JH108sz4', 'JH108sz5', 'JH108sz6', 'JH108sz7'\n",
    "           ]\n",
    "EXTERNAL = 1\n",
    "\n",
    "# initialize directory with data\n",
    "dataDir = '../fragility_dataanalysis/data/'\n",
    "iiDataDir = '../fragility_dataanalysis/data/interictal_data/'\n",
    "newDataDir = '../fragility_dataanalysis/data/json/' # new directory to save data\n",
    "\n",
    "if EXTERNAL:\n",
    "    dataDir = '/Volumes/NIL_PASS/data/'\n",
    "    iiDataDir = '/Volumes/NIL_PASS/data/interictal_data/'\n",
    "    newDataDir = '/Volumes/NIL_PASS/data/json/'\n",
    "    \n",
    "# check if new dataDir exists, if not create it\n",
    "if not os.path.exists(newDataDir):\n",
    "    os.makedirs(newDataDir)\n",
    "    \n",
    "print 'EXTERNAL IS: ', EXTERNAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting patient  pt2sz4\n",
      "Problem with  pt2sz4\n",
      "Starting patient  pt3sz2\n",
      "Starting patient  pt3sz4\n",
      "Starting patient  pt6sz3\n",
      "Starting patient  pt6sz4\n",
      "Starting patient  pt6sz5\n",
      "Starting patient  pt7sz19\n",
      "Starting patient  pt7sz21\n",
      "Starting patient  pt7sz22\n",
      "Starting patient  pt8sz1\n",
      "Starting patient  pt8sz2\n",
      "Starting patient  pt8sz3\n",
      "Starting patient  JH101sz1\n",
      "Starting patient  JH101sz2\n",
      "Starting patient  JH101sz3\n",
      "Starting patient  JH101sz4\n",
      "Starting patient  JH102sz1\n",
      "Starting patient  JH102sz2\n",
      "Starting patient  JH102sz3\n",
      "Starting patient  JH102sz4\n",
      "Starting patient  JH102sz5\n",
      "Starting patient  JH102sz6\n",
      "Starting patient  JH103sz1\n",
      "Starting patient  JH103sz2\n",
      "Starting patient  JH103sz3\n",
      "Starting patient  JH104sz1\n",
      "Starting patient  JH104sz2\n",
      "Starting patient  JH104sz3\n",
      "Starting patient  JH105sz1\n",
      "Starting patient  JH105sz2\n",
      "Starting patient  JH105sz3\n",
      "Starting patient  JH105sz4\n",
      "Starting patient  JH105sz5\n",
      "Starting patient  JH106sz1\n",
      "Starting patient  JH106sz2\n",
      "Starting patient  JH106sz3\n",
      "Starting patient  JH106sz4\n",
      "Starting patient  JH106sz5\n",
      "Starting patient  JH106sz6\n",
      "Starting patient  JH107sz1\n",
      "Starting patient  JH107sz2\n",
      "Starting patient  JH107sz3\n",
      "Starting patient  JH107sz4\n",
      "Starting patient  JH107sz5\n",
      "Starting patient  JH107sz6\n",
      "Starting patient  JH107sz7\n",
      "Starting patient  JH107sz8\n",
      "Starting patient  JH107sz9\n",
      "Starting patient  JH108sz1\n",
      "Starting patient  JH108sz2\n",
      "Starting patient  JH108sz3\n",
      "Starting patient  JH108sz4\n",
      "Starting patient  JH108sz5\n",
      "Starting patient  JH108sz6\n",
      "Starting patient  JH108sz7\n"
     ]
    }
   ],
   "source": [
    "# get mat files in a patient's directory\n",
    "patient = patients[0]\n",
    "\n",
    "for patient in patients:\n",
    "    print \"Starting patient \", patient\n",
    "    \n",
    "    patientDir = dataDir + patient + '/'\n",
    "    matFiles = []\n",
    "    for file in os.listdir(patientDir):\n",
    "        if file.endswith('.mat'):\n",
    "            matFiles.append(file)\n",
    "\n",
    "    if len(matFiles) > 1:\n",
    "        print \"There is too many .mat files in this directory!\"\n",
    "        print \"Check patient \", patient\n",
    "\n",
    "    matFile = patientDir + matFiles[0]\n",
    "    data = loadmat(matFile)\n",
    "\n",
    "    fileName = newDataDir + patient + 'raw.json.bz2'\n",
    "    try:\n",
    "        convertMatToJSON(data, fileName)\n",
    "    except:\n",
    "        print \"Problem with \", patient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
